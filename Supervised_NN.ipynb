{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Sentiment Analysis with Wine Reviews <\\h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intro for final model...\n",
    "\n",
    "This module uses the <a href=\" https://www.kaggle.com/zynicide/wine-reviewsdata \">Wine Reviews </a> dataset availible on Kaggle to determine sentiment analysis of the wine after reading only a short review.  The goal being to deveolop an RNN that can organize text data. Results will be ran against a straight-forward logistic regression model test the strength of the sentiment analysis model.\n",
    "\n",
    "\n",
    "    <li> Log Reg Model </li>\n",
    "    <li> RNN for sentiment analysis\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# varieties = X_.variety\n",
    "# varieties = set(varieties)\n",
    "# len(varieties)\n",
    "# desc = X_.description\n",
    "# stop_words = list(stopwords.words('english')) \n",
    "# stop_words.append(varieties)\n",
    "\n",
    "# def enc_with_stop_words()\n",
    "#     split_dict = {}\n",
    "#     i = 0\n",
    "#     while i < desc.shape[0]:     \n",
    "#         word_tokens = word_tokenize(desc[0]) \n",
    "#         filtered_sentence = [w for w in word_tokens if not w in stop_words] \n",
    "#         split_dict.update({i: filtered_sentence})\n",
    "#         i += 1\n",
    "#         if i > 5:\n",
    "#             break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "Name: points_bivariate, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr, x_ts, y_tr, y_ts = train_test_split(X, y, test_size=0.35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn import tree \n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 20}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_depth\": [1, 2, 5, 10],\n",
    "    \"min_samples_split\": [1.0, 5, 10, 20]\n",
    "}\n",
    "treeclf = DecisionTreeClassifier(criterion='entropy')\n",
    "treeclf.fit(x_tr, y_tr)\n",
    "y_pred = treeclf.predict(x_ts)\n",
    "\n",
    "gs_tree = GridSearchCV(treeclf, param_grid, cv=4)\n",
    "gs_tree.fit(x_tr, y_tr)\n",
    "\n",
    "gs_tree.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is : 75.563\n",
      "F1 Score : 0.678100646058464\n"
     ]
    }
   ],
   "source": [
    "# Metrics\n",
    "acc = accuracy_score(y_ts, y_pred) * 100\n",
    "print(\"Accuracy is : {0}\".format(round(acc, 4)))\n",
    "f1 = f1_score(y_ts, y_pred)\n",
    "print(f'F1 Score : {f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Interpret Results </h4>\n",
    "\n",
    "The accuracy is better than a 50/50 guess. Enough so to warrent further tweaking on it's own.  The bar is set.\n",
    "\n",
    " make this into a table\n",
    "Common-Sense Baseline = 50%  <- run code to express in same terms.  using sample data and y, y_pred\n",
    "Decision Tree Accuracy = acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Recurrent Neural Network for Sequential Data </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_nn = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr, x_ts, y_tr, y_ts = train_test_split(X_nn, y, test_size = .35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 40, 128)           16628096  \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 40, 50)            35800     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_4 (Glob (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 16,666,497\n",
      "Trainable params: 16,666,497\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm_model = Sequential()\n",
    "lstm_model.add(Embedding(input_shape[0], 128, input_length=maxlen))\n",
    "lstm_model.add(LSTM(50, return_sequences=True))\n",
    "lstm_model.add(GlobalMaxPool1D())\n",
    "lstm_model.add(Dropout(0.5))\n",
    "lstm_model.add(Dense(50, activation='relu'))\n",
    "lstm_model.add(Dropout(0.25))\n",
    "lstm_model.add(Dense(1, activation='softmax'))\n",
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9.97248627144485,\n",
       " 9.97248627144485,\n",
       " 9.97248627144485,\n",
       " 9.97248627144485,\n",
       " 9.97248627144485,\n",
       " 9.97248627144485,\n",
       " 9.97248627144485,\n",
       " 9.97248627144485,\n",
       " 9.97248627144485,\n",
       " 9.97248627144485,\n",
       " 9.97248627144485]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history['val_loss']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> GloVe </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_corpus = data_final['description'].map(word_tokenize).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51497"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_vocabulary = set(word for description in description_corpus for word in description)\n",
    "\n",
    "len(total_vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_dir = \"C:\\Users\\Mark\\Documents\\DataSci\\glove_dir\"\n",
    "\n",
    "f = open(os.path.join(glove_dir, 'glove.840B.300d.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19411 word vectors.\n"
     ]
    }
   ],
   "source": [
    "glove_dir = r'C:\\Users\\Mark\\Documents\\DataSci\\glove_dir\\glove.6B.50d.txt' #r prefix converts from a normal string to a raw string\n",
    "glove = {}\n",
    "with open(glove_dir, 'rb') as f:\n",
    "    for line in f:\n",
    "        parts = line.split()\n",
    "        word = parts[0].decode('utf-8')\n",
    "        if word in total_vocabulary:\n",
    "            vector = np.array(parts[1:], dtype=np.float32)\n",
    "            glove[word] = vector\n",
    "print(f'Found {len(glove)} word vectors.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Aromas',\n",
       " 'include',\n",
       " 'tropical',\n",
       " 'fruit',\n",
       " ',',\n",
       " 'broom',\n",
       " ',',\n",
       " 'brimstone',\n",
       " 'and',\n",
       " 'dried',\n",
       " 'herb',\n",
       " '.',\n",
       " 'The',\n",
       " 'palate',\n",
       " 'is',\n",
       " \"n't\",\n",
       " 'overly',\n",
       " 'expressive',\n",
       " ',',\n",
       " 'offering',\n",
       " 'unripened',\n",
       " 'apple',\n",
       " ',',\n",
       " 'citrus',\n",
       " 'and',\n",
       " 'dried',\n",
       " 'sage',\n",
       " 'alongside',\n",
       " 'brisk',\n",
       " 'acidity',\n",
       " '.']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description_corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 38 \n",
      " missing 5\n",
      "found [',', 'supple', 'plum', 'envelopes', 'an', 'oaky', 'structure', 'in', 'this', ',', 'supported', 'by', '15', '%', '.', 'and', 'chocolate', 'complete', 'the', 'picture', ',', 'finishing', 'strong', 'at', 'the', 'end', ',', 'resulting', 'in', 'a', 'wine', 'of', 'attractive', 'flavor', 'and', 'immediate', 'accessibility', '.'] \n",
      " missing ['Soft', 'Cabernet', 'Merlot', 'Coffee', 'value-priced']\n"
     ]
    }
   ],
   "source": [
    "found = []\n",
    "missing = []\n",
    "for word in description_corpus[10]:\n",
    "    if word in glove:\n",
    "        found.append(word)\n",
    "    else:\n",
    "        missing.append(word)\n",
    "        \n",
    "print(f\"found {len(found)} \\nmissing {len(missing)}\")\n",
    "print(f\"found {found} \\n missing {missing}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.54015 , -0.29931 , -0.67591 ,  0.15784 ,  0.90241 , -0.89567 ,\n",
       "       -1.1267  , -0.69013 ,  0.7116  ,  0.71231 ,  0.11031 , -0.37268 ,\n",
       "        0.93846 , -0.42899 ,  1.0807  ,  0.43785 , -0.38785 ,  0.65528 ,\n",
       "        0.34501 , -1.3793  ,  1.114   , -0.20227 ,  0.53612 ,  0.67394 ,\n",
       "       -0.52717 , -0.30703 , -0.14833 ,  0.78579 ,  0.84364 ,  0.56468 ,\n",
       "        2.1954  , -0.097544, -0.41744 ,  1.0296  ,  0.083024, -0.1552  ,\n",
       "       -1.1257  ,  0.74416 ,  1.1534  ,  0.24415 ,  0.057113,  0.63826 ,\n",
       "       -0.35989 , -0.031659,  0.88827 ,  0.78731 , -0.47028 , -0.69737 ,\n",
       "        0.12029 , -0.41486 ], dtype=float32)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove['coffee']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'max_words' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-115-0649b63be0e0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0membedding_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m128\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mword_index\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mmax_words\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[0membedding_vector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0membedding_index\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0membedding_vector\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'max_words' is not defined"
     ]
    }
   ],
   "source": [
    "embedding_matrix = np.zeros((10000, 128))\n",
    "for word, i in word_index.items():\n",
    "    if i < 10000:\n",
    "        embedding_vector = embedding_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# parse glove\n",
    "# pretrained\n",
    "# plot results\n",
    "# simple RNN\n",
    "# plot results\n",
    "# RNN with LSTM/GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Summary </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Common Sense non-machine-learning baseline:\n",
    "Decision Tree accuracy:\n",
    "Best RNN accuracy:\n",
    "\n",
    "Advantaves of Decision Tree - \n",
    "Advantages of RNN - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
